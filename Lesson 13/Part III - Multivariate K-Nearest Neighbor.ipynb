{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Recap\n",
    "==\n",
    "\n",
    "In the last mission, we explored how to use a simple k-nearest neighbors machine learning model that used just one feature, or attribute, of the listing to predict the rent price. We first relied on the <span style=\"background-color: #F9EBEA; color:##C0392B\">accommodates</span> column, which describes the number of people a living space can comfortably accommodate. Then, we switched to the <span style=\"background-color: #F9EBEA; color:##C0392B\">bathrooms</span> column and observed an improvement in accuracy. While these were good features to become familiar with the basics of machine learning, it's clear that using just a single feature to compare listings doesn't reflect the reality of the market. An apartment that can accommodate 4 guests in a popular part of Washington D.C. will rent for much higher than one that can accommodate 4 guests in a crime ridden area.\n",
    "\n",
    "There are 2 ways we can tweak the model to try to improve the accuracy (decrease the RMSE during validation):\n",
    "\n",
    "- increase the number of attributes the model uses to calculate similarity when ranking the closest neighbors\n",
    "- increase <span style=\"background-color: #F9EBEA; color:##C0392B\">k</span>, the number of nearby neighbors the model uses when computing the prediction\n",
    "\n",
    "\n",
    "In this mission, we'll focus on increasing the number of attributes the model uses. When selecting more attributes to use in the model, we need to watch out for columns that don't work well with the distance equation. This includes columns containing:\n",
    "\n",
    "- non-numerical values (e.g. city or state)\n",
    "    - Euclidean distance equation expects numerical values\n",
    "- missing values\n",
    "    - distance equation expects a value for each observation and attribute\n",
    "- non-ordinal values (e.g. latitude or longitude)\n",
    "    - ranking by Euclidean distance doesn't make sense if all attributes aren't ordinal\n",
    "    \n",
    "In the following code screen, we've read the <span style=\"background-color: #F9EBEA; color:##C0392B\">dc_airbnb.csv</span> dataset from the last mission into pandas and brought over the data cleaning changes we made. Let's first look at the first row's values to identify any columns containing non-numerical or non-ordinal values. In the next screen, we'll drop those columns and then look for missing values in each of the remaining columns.\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise Start.</b>\n",
    "</div>\n",
    "\n",
    "**Description**: \n",
    "\n",
    "1. Use the <span style=\"background-color: #F9EBEA; color:##C0392B\">DataFrame.info()</span> method to return the number of non-null values in each column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>room_type</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>security_deposit</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>100%</td>\n",
       "      <td>100%</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$300.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>149</td>\n",
       "      <td>38.913548</td>\n",
       "      <td>-77.031981</td>\n",
       "      <td>Washington</td>\n",
       "      <td>20009</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    host_response_rate host_acceptance_rate  host_listings_count  \\\n",
       "574               100%                 100%                    1   \n",
       "\n",
       "     accommodates     room_type  bedrooms  bathrooms  beds  price  \\\n",
       "574             2  Private room       1.0        1.0   1.0  125.0   \n",
       "\n",
       "    cleaning_fee security_deposit  minimum_nights  maximum_nights  \\\n",
       "574          NaN          $300.00               1               4   \n",
       "\n",
       "     number_of_reviews   latitude  longitude        city zipcode state  \n",
       "574                149  38.913548 -77.031981  Washington   20009    DC  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "dc_listings = pd.read_csv('dc_airbnb.csv')\n",
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "\n",
    "dc_listings.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Removing features\n",
    "==\n",
    "\n",
    "The following columns contain non-numerical values:\n",
    "\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">room_type</span>: e.g. **Private room**\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">city</span>: e.g. **Washington**\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">state</span>: e.g. **DC**\n",
    "\n",
    "while these columns contain numerical but non-ordinal values:\n",
    "\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">latitude</span>: e.g. **38.913458**\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">longitude</span>: e.g. **-77.031**\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">zipcode</span>: e.g. **20009**\n",
    "\n",
    "\n",
    "Geographic values like these aren't ordinal, because a smaller numerical value doesn't directly correspond to a smaller value in a meaningful way. For example, the zip code 20009 isn't smaller or larger than the zip code 75023 and instead both are unique, identifier values. Latitude and longitude value pairs describe a point on a geographic coordinate system and different equations are used in those cases (e.g. [haversine](https://en.wikipedia.org/wiki/Haversine_formula)).\n",
    "\n",
    "While we could convert the <span style=\"background-color: #F9EBEA; color:##C0392B\">host_response_rate</span> and <span style=\"background-color: #F9EBEA; color:##C0392B\">host_acceptance_rate</span> columns to be numerical (right now they're object data types and contain the <span style=\"background-color: #F9EBEA; color:##C0392B\">%</span> sign), these columns describe the host and not the living space itself. Since a host could have many living spaces and we don't have enough information to uniquely group living spaces to the hosts themselves, let's avoid using any columns that don't directly describe the living space or the listing itself:\n",
    "\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">host_response_rate</span>\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">host_acceptance_rate</span>\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">host_listings_count</span>\n",
    "\n",
    "Let's remove these 9 columns from the Dataframe\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise Start.</b>\n",
    "</div>\n",
    "\n",
    "**Description**: \n",
    "\n",
    "1. Remove the 9 columns we discussed above from <span style=\"background-color: #F9EBEA; color:##C0392B\">dc_listings</span>:\n",
    "    - 3 containing non-numerical values\n",
    "    - 3 containing numerical but non-ordinal values\n",
    "    - 3 describing the host instead of the living space itself\n",
    "2. Verify the number of null values of each remain columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>security_deposit</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$300.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accommodates  bedrooms  bathrooms  beds  price cleaning_fee  \\\n",
       "574             2       1.0        1.0   1.0  125.0          NaN   \n",
       "\n",
       "    security_deposit  minimum_nights  maximum_nights  number_of_reviews  \n",
       "574          $300.00               1               4                149  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_listings = dc_listings.drop([\n",
    "    'host_response_rate',\n",
    "    'host_acceptance_rate',\n",
    "    'host_listings_count',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'zipcode',\n",
    "    'room_type',\n",
    "    'city',\n",
    "    'state'\n",
    "], axis=1)\n",
    "dc_listings.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Handling missing values\n",
    "==\n",
    "\n",
    "Of the remaining columns, 3 columns have a few missing values (less than 1% of the total number of rows):\n",
    "\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">bedrooms</span>\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">bathrooms</span>\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">beds</span>\n",
    "\n",
    "Since the number of rows containing missing values for one of these 3 columns is low, we can select and remove those rows without losing much information. There are also 2 columns have a large number of missing values:\n",
    "\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">cleaning_fee</span> - 37.3% of the rows\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">security_deposit</span> - 61.7% of the rows\n",
    "\n",
    "and we can't handle these easily. We can't just remove the rows containing missing values for these 2 columns because we'd miss out on the majority of the observations in the dataset. Instead, let's remove these 2 columns entirely from consideration.\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise Start.</b>\n",
    "</div>\n",
    "\n",
    "**Description**: \n",
    "\n",
    "1. Drop the <span style=\"background-color: #F9EBEA; color:##C0392B\">cleaning_fee</span> and <span style=\"background-color: #F9EBEA; color:##C0392B\">security_deposit</span> columns from <span style=\"background-color: #F9EBEA; color:##C0392B\">dc_listings</span>.\n",
    "2. Then, remove all rows that contain a missing value for the <span style=\"background-color: #F9EBEA; color:##C0392B\">bedrooms</span>, <span style=\"background-color: #F9EBEA; color:##C0392B\">bathrooms</span>, or <span style=\"background-color: #F9EBEA; color:##C0392B\">beds</span> column from <span style=\"background-color: #F9EBEA; color:##C0392B\">dc_listings</span>.\n",
    "    - You can accomplish this by using the [Dataframe method dropna()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html) and setting the <span style=\"background-color: #F9EBEA; color:##C0392B\">axis</span> parameter to **0**.\n",
    "    - Since only the <span style=\"background-color: #F9EBEA; color:##C0392B\">bedrooms</span>, <span style=\"background-color: #F9EBEA; color:##C0392B\">bathrooms</span> and <span style=\"background-color: #F9EBEA; color:##C0392B\">beds</span> columns contain any missing values, rows containing missing values in these columns will be removed.\n",
    "3. Display the null value counts for the updated <span style=\"background-color: #F9EBEA; color:##C0392B\">dc_listings</span> Dataframe to confirm that there are no missing values left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accommodates         0\n",
       "bedrooms             0\n",
       "bathrooms            0\n",
       "beds                 0\n",
       "price                0\n",
       "minimum_nights       0\n",
       "maximum_nights       0\n",
       "number_of_reviews    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_listings = dc_listings.drop([\n",
    "    'cleaning_fee',\n",
    "    'security_deposit'\n",
    "], axis=1)\n",
    "\n",
    "dc_listings = dc_listings.dropna(axis=0)\n",
    "dc_listings.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Normalize columns\n",
    "==\n",
    "\n",
    "Here's how the <span style=\"background-color: #F9EBEA; color:##C0392B\">dc_listings</span> Dataframe looks like after all the changes we made:\n",
    "\n",
    "| accommodates | bedrooms | bathrooms | beds | price | minimum_nights | maximum_nights | number_of_reviews |\n",
    "|--------------|----------|-----------|------|-------|----------------|----------------|-------------------|\n",
    "| 2            | 1.0      | 1.0       | 1.0  | 125.0 | 1              | 4              | 149               |\n",
    "| 2            | 1.0      | 1.5       | 1.0  | 85.0  | 1              | 30             | 49                |\n",
    "| 1            | 1.0      | 0.5       | 1.0  | 50.0  | 1              | 1125           | 1                 |\n",
    "| 2            | 1.0      | 1.0       | 1.0  | 209.0 | 4              | 730            | 2                 |\n",
    "| 12           | 5.0      | 2.0       | 5.0  | 215.0 | 2              | 1825           | 34                |\n",
    "\n",
    "You may have noticed that while the <span style=\"background-color: #F9EBEA; color:##C0392B\">accommodates</span>, <span style=\"background-color: #F9EBEA; color:##C0392B\">bedrooms</span>, <span style=\"background-color: #F9EBEA; color:##C0392B\">bathrooms</span>, <span style=\"background-color: #F9EBEA; color:##C0392B\">beds</span>, and <span style=\"background-color: #F9EBEA; color:##C0392B\">minimum_nights</span> columns hover between 0 and 12 (at least in the first few rows), the values in the <span style=\"background-color: #F9EBEA; color:##C0392B\">maximum_nights</span> and <span style=\"background-color: #F9EBEA; color:##C0392B\">number_of_reviews</span> columns span much larger ranges. For example, the <span style=\"background-color: #F9EBEA; color:##C0392B\">maximum_nights</span> column has values as low as 4 and high as 1825, in the first few rows itself. If we use these 2 columns as part of a k-nearest neighbors model, these attributes could end up having an outsized effect on the distance calculations because of the largeness of the values.\n",
    "\n",
    "For example, 2 living spaces could be identical across every attribute but be vastly different just on the <span style=\"background-color: #F9EBEA; color:##C0392B\">maximum_nights</span> column. If one listing had a <span style=\"background-color: #F9EBEA; color:##C0392B\">maximum_nights</span> value of 1825 and the other a <span style=\"background-color: #F9EBEA; color:##C0392B\">maximum_nights</span> value of 4, because of the way Euclidean distance is calculated, these listings would be considered very far apart because of the outsized effect the largeness of the values had on the overall Euclidean distance. To prevent any single column from having too much of an impact on the distance, we can **normalize** all of the columns to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "Normalizing the values in each columns to the [standard normal distribution](https://en.wikipedia.org/wiki/Normal_distribution#Standard_normal_distribution) (mean of 0, standard deviation of 1) preserves the distribution of the values in each column while aligning the scales. To normalize the values in a column to the standard normal distribution, you need to:\n",
    "\n",
    "- from each value, subtract the mean of the column\n",
    "- divide each value by the standard deviation of the column\n",
    "\n",
    "Here's the mathematical formula describing the transformation that needs to be applied for all values in a column:\n",
    "\n",
    "$\\displaystyle z= \\frac{x − \\mu}{\\sigma}$\n",
    "\n",
    "where x is a value in a specific column, $\\mu$ is the mean of all the values in the column, and $\\sigma$ is the standard deviation of all the values in the column. Here's what the corresponding code, using pandas, looks like:\n",
    "\n",
    ">```python\n",
    "# Subtract each value in the column by the mean.\n",
    "first_transform = dc_listings['maximum_nights'] - dc_listings['maximum_nights'].mean()\n",
    "# Divide each value in the column by the standard deviation.\n",
    "normalized_col = first_transform / dc_listings['maximum_nights'].std()\n",
    "```\n",
    "\n",
    "To apply this transformation across all of the columns in a Dataframe, you can use the corresponding Dataframe methods mean() and std():\n",
    "\n",
    ">```python\n",
    "normalized_listings = (dc_listings - dc_listings.mean()) / (dc_listings.std())\n",
    "```\n",
    "\n",
    "These methods were written with mass column transformation in mind and when you call <span style=\"background-color: #F9EBEA; color:##C0392B\">mean()</span> or <span style=\"background-color: #F9EBEA; color:##C0392B\">std()</span>, the appropriate column means and column standard deviations are used for each value in the Dataframe. Let's now normalize all of the feature columns in <span style=\"background-color: #F9EBEA; color:##C0392B\">dc_listings</span>.\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise Start.</b>\n",
    "</div>\n",
    "\n",
    "**Description**: \n",
    "\n",
    "1. Normalize all of the feature columns in <span style=\"background-color: #F9EBEA; color:##C0392B\">dc_listings</span> and assign the new Dataframe containing just the normalized feature columns to <span style=\"background-color: #F9EBEA; color:##C0392B\">normalized_listings</span>.\n",
    "2. Add the price column from <span style=\"background-color: #F9EBEA; color:##C0392B\">dc_listings</span> to <span style=\"background-color: #F9EBEA; color:##C0392B\">normalized_listings</span>.\n",
    "3. Display the first 3 rows in <span style=\"background-color: #F9EBEA; color:##C0392B\">normalized_listings</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>-0.596544</td>\n",
       "      <td>-0.249467</td>\n",
       "      <td>-0.439151</td>\n",
       "      <td>-0.546858</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-0.341375</td>\n",
       "      <td>-0.016604</td>\n",
       "      <td>4.579650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>-0.596544</td>\n",
       "      <td>-0.249467</td>\n",
       "      <td>0.412923</td>\n",
       "      <td>-0.546858</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.341375</td>\n",
       "      <td>-0.016603</td>\n",
       "      <td>1.159275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>-1.095499</td>\n",
       "      <td>-0.249467</td>\n",
       "      <td>-1.291226</td>\n",
       "      <td>-0.546858</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.341375</td>\n",
       "      <td>-0.016573</td>\n",
       "      <td>-0.482505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accommodates  bedrooms  bathrooms      beds  price  minimum_nights  \\\n",
       "574      -0.596544 -0.249467  -0.439151 -0.546858  125.0       -0.341375   \n",
       "1593     -0.596544 -0.249467   0.412923 -0.546858   85.0       -0.341375   \n",
       "3091     -1.095499 -0.249467  -1.291226 -0.546858   50.0       -0.341375   \n",
       "\n",
       "      maximum_nights  number_of_reviews  \n",
       "574        -0.016604           4.579650  \n",
       "1593       -0.016603           1.159275  \n",
       "3091       -0.016573          -0.482505  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_listings = (dc_listings - dc_listings.mean()) / (dc_listings.std())\n",
    "normalized_listings['price'] = dc_listings.price\n",
    "normalized_listings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Euclidean distance for multivariate case\n",
    "==\n",
    "\n",
    "In the last mission, we trained 2 univariate k-nearest neighbors models. The first one used the <span style=\"background-color: #F9EBEA; color:##C0392B\">accommodates</span> attribute while the second one used the <span style=\"background-color: #F9EBEA; color:##C0392B\">bathrooms</span> attribute. Let's now train a model that uses **both** attributes when determining how similar 2 living spaces are. Let's refer to the Euclidean distance equation again to see what the distance calculation using 2 attributes would look like:\n",
    "\n",
    "$\\displaystyle d = \\sqrt{(q_1 - p_1)^2 + (q_2 - p_2)^2 + \\ldots + (q_n - p_n)^2}$\n",
    "\n",
    "Since we're using 2 attributes, the distance calculation would look like:\n",
    "\n",
    "$\\displaystyle d = \\sqrt{(accommodates_1 - accomodates_2)^2 + (bathrooms_1 - bathrooms_2)^2}$\n",
    "\n",
    "\n",
    "To find the distance between 2 living spaces, we need to calculate the squared difference between both <span style=\"background-color: #F9EBEA; color:##C0392B\">accommodates</span> values, the squared difference between both <span style=\"background-color: #F9EBEA; color:##C0392B\">bathrooms</span> values, add them together, and then take the square root of the resulting sum. Here's what the Euclidean distance between the first 2 rows in <span style=\"background-color: #F9EBEA; color:##C0392B\">normalized_listings</span> looks like:\n",
    "\n",
    "<img width=\"600\" alt=\"creating a repo\" src=\"https://drive.google.com/uc?export=view&id=15uoTMT1rzRLx9T8kIbsOWw7HaTmdBP0o\">\n",
    "\n",
    "\n",
    "So far, we've been calculating Euclidean distance ourselves by writing the logic for the equation ourselves. We can instead use the [distance.euclidean()](http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.euclidean.html) function from <span style=\"background-color: #F9EBEA; color:##C0392B\">scipy.spatial</span>, which takes in 2 vectors as the parameters and calculates the Euclidean distance between them. The <span style=\"background-color: #F9EBEA; color:##C0392B\">euclidean()</span> function expects:\n",
    "\n",
    "- both of the vectors to be represented using a **list-like** object (Python list, NumPy array, or pandas Series)\n",
    "- both of the vectors must be 1-dimensional and have the same number of elements\n",
    "\n",
    "Here's a simple example:\n",
    "\n",
    ">```python\n",
    "from scipy.spatial import distance\n",
    "first_listing = [-0.596544, -0.439151]\n",
    "second_listing = [-0.596544, 0.412923]\n",
    "dist = distance.euclidean(first_listing, second_listing)\n",
    "```\n",
    "\n",
    "Let's use the <span style=\"background-color: #F9EBEA; color:##C0392B\">euclidean()</span> function to calculate the Euclidean distance between 2 rows in our dataset to practice.\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise Start.</b>\n",
    "</div>\n",
    "\n",
    "**Description**: \n",
    "\n",
    "1. Calculate the Euclidean distance using only the <span style=\"background-color: #F9EBEA; color:##C0392B\">accommodates</span> and <span style=\"background-color: #F9EBEA; color:##C0392B\">bathrooms</span> features between the first row and fifth row in <span style=\"background-color: #F9EBEA; color:##C0392B\">normalized_listings</span> using the <span style=\"background-color: #F9EBEA; color:##C0392B\">distance.euclidean()</span> function.\n",
    "2. Assign the distance value to <span style=\"background-color: #F9EBEA; color:##C0392B\">first_fifth_distance</span> and display using the <span style=\"background-color: #F9EBEA; color:##C0392B\">print</span> function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.300197080884489"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "first_fifth_distance = distance.euclidean(normalized_listings.iloc[0:5].accommodates, normalized_listings.iloc[0:5].bathrooms) \n",
    "first_fifth_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Introduction to scikit-learn\n",
    "==\n",
    "\n",
    "So far, we've been writing functions from scratch to train the k-nearest neighbor models. While this is helpful deliberate practice to understand how the mechanics work, you can be more productive and iterate quicker by using a library that handles most of the implementation. In this screen, we'll learn about the [scikit-learn library](http://scikit-learn.org/), which is the most popular machine learning in Python. Scikit-learn contains functions for all of the major machine learning algorithms and a simple, unified workflow. Both of these properties allow data scientists to be incredibly productive when training and testing different models on a new dataset.\n",
    "\n",
    "The scikit-learn workflow consists of 4 main steps:\n",
    "\n",
    "- instantiate the specific machine learning model you want to use\n",
    "- fit the model to the training data\n",
    "- use the model to make predictions\n",
    "- evaluate the accuracy of the predictions\n",
    "\n",
    "\n",
    "We'll focus on the first 3 steps in this screen and the next screen. Each model in scikit-learn is implemented as a [separate class](http://scikit-learn.org/dev/modules/classes.html) and the first step is to identify the class we want to create an instance of. In our case, we want to use the [KNeighborsRegressor class](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor).\n",
    "Any model that helps us predict numerical values, like listing price in our case, is known as a **regression** model. The other main class of machine learning models is called classification, where we're trying to predict a label from a fixed set of labels (e.g. blood type or gender). The word **regressor** from the class name <span style=\"background-color: #F9EBEA; color:##C0392B\">KNeighborsRegressor</span> refers to the regression model class that we just discussed.\n",
    "\n",
    "Scikit-learn uses a similar object-oriented style to Matplotlib and you need to instantiate an empty model first by calling the constructor:\n",
    "\n",
    ">```python\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor()\n",
    "```\n",
    "\n",
    "If you refer to the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor), you'll notice that by default:\n",
    "\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">n_neighbors:</span> the number of neighbors, is set to **5**\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">algorithm:</span> for computing nearest neighbors, is set to **auto**\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">p:</span> set to **2**, corresponding to Euclidean distance\n",
    "\n",
    "Let's set the <span style=\"background-color: #F9EBEA; color:##C0392B\">algorithm</span> parameter to <span style=\"background-color: #F9EBEA; color:##C0392B\">brute</span> and leave the <span style=\"background-color: #F9EBEA; color:##C0392B\">n_neighbors</span> value as **5**, which matches the implementation we wrote in the last mission. If we leave the <span style=\"background-color: #F9EBEA; color:##C0392B\">algorithm</span> parameter set to the default value of <span style=\"background-color: #F9EBEA; color:##C0392B\">auto</span>, scikit-learn will try to use tree-based optimizations to improve performance (which are outside of the scope of this mission):\n",
    "\n",
    ">```python\n",
    "knn = KNeighborsRegressor(algorithm='brute')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Fitting a model and making predictions\n",
    "==\n",
    "\n",
    "Now, we can fit the model to the data using the [fit method](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor.fit). For all models, the <span style=\"background-color: #F9EBEA; color:##C0392B\">fit</span> method takes in 2 required parameters:\n",
    "\n",
    "- matrix-like object, containing the feature columns we want to use from the training set.\n",
    "- list-like object, containing correct target values.\n",
    "\n",
    "Matrix-like object means that the method is flexible in the input and either a Dataframe or a NumPy 2D array of values is accepted. This means you can select the columns you want to use from the Dataframe and use that as the first parameter to the <span style=\"background-color: #F9EBEA; color:##C0392B\">fit</span> method.\n",
    "\n",
    "If you recall from earlier in the mission, all of the following are acceptable list-like objects:\n",
    "\n",
    "- NumPy array\n",
    "- Python list\n",
    "- pandas Series object (e.g. when selecting a column)\n",
    "\n",
    "You can select the target column from the Dataframe and use that as the second parameter to the <span style=\"background-color: #F9EBEA; color:##C0392B\">fit</span> method:\n",
    "\n",
    ">```python\n",
    "# Split full dataset into train and test sets.\n",
    "train_df = normalized_listings.iloc[0:2792]\n",
    "test_df = normalized_listings.iloc[2792:]\n",
    "# Matrix-like object, containing just the 2 columns of interest from training set.\n",
    "train_features = train_df[['accommodates', 'bathrooms']]\n",
    "# List-like object, containing just the target column, `price`.\n",
    "train_target = normalized_listings['price']\n",
    "# Pass everything into the fit method.\n",
    "knn.fit(train_features, train_target)\n",
    "```\n",
    "\n",
    "\n",
    "When the <span style=\"background-color: #F9EBEA; color:##C0392B\">fit</span> method is called, scikit-learn stores the training data we specified within the KNearestNeighbors instance (<span style=\"background-color: #F9EBEA; color:##C0392B\">knn</span>). If you try passing in data containing missing values or non-numerical values into the <span style=\"background-color: #F9EBEA; color:##C0392B\">fit</span> method, scikit-learn will return an error. Scikit-learn contains many such features that help prevent us from making common mistakes.\n",
    "\n",
    "Now that we specified the training data we want used to make predictions, we can use the [predict method](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor.predict) to make predictions on the test set. The <span style=\"background-color: #F9EBEA; color:##C0392B\">predict</span> method has only one required parameter:\n",
    "\n",
    "- matrix-like object, containing the feature columns from the dataset we want to make predictions on\n",
    "\n",
    "The number of feature columns you use during both training and testing need to match or scikit-learn will return an error:\n",
    "\n",
    ">```python\n",
    "predictions = knn.predict(test_df[['accommodates', 'bathrooms']])\n",
    "```\n",
    "\n",
    "The <span style=\"background-color: #F9EBEA; color:##C0392B\">predict()</span> method returns a NumPy array containing the predicted <span style=\"background-color: #F9EBEA; color:##C0392B\">price</span> values for the test set. You now have everything you need to practice the entire scikit-learn workflow.\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise Start.</b>\n",
    "</div>\n",
    "\n",
    "**Description**: \n",
    "\n",
    "1. Create an instance of the [KNeighborsRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor) class with the following parameters:\n",
    "    - <span style=\"background-color: #F9EBEA; color:##C0392B\">n_neighbors</span>: 5\n",
    "    - <span style=\"background-color: #F9EBEA; color:##C0392B\">algorithm</span>: brute\n",
    "2. Use the <span style=\"background-color: #F9EBEA; color:##C0392B\">fit</span> method to specify the data we want the k-nearest neighbor model to use. Use the following parameters:\n",
    "    - training data, feature columns: just the <span style=\"background-color: #F9EBEA; color:##C0392B\">accommodates</span> and <span style=\"background-color: #F9EBEA; color:##C0392B\">bathrooms</span> columns, in that order, from <span style=\"background-color: #F9EBEA; color:##C0392B\">train_df</span>.\n",
    "    - training data, target column: the <span style=\"background-color: #F9EBEA; color:##C0392B\">price</span> column from <span style=\"background-color: #F9EBEA; color:##C0392B\">train_df</span>.\n",
    "3. Call the <span style=\"background-color: #F9EBEA; color:##C0392B\">predict</span> method to make predictions on:\n",
    "    - the <span style=\"background-color: #F9EBEA; color:##C0392B\">accommodates</span> and <span style=\"background-color: #F9EBEA; color:##C0392B\">bathrooms</span> columns from <span style=\"background-color: #F9EBEA; color:##C0392B\">test_df</span>\n",
    "    - assign the resulting NumPy array of predicted price values to <span style=\"background-color: #F9EBEA; color:##C0392B\">predictions</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3671,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "train_df = normalized_listings.iloc[0:2792]\n",
    "test_df = normalized_listings.iloc[2792:]\n",
    "\n",
    "knn = KNeighborsRegressor(algorithm='brute')\n",
    "\n",
    "# Matrix-like object, containing just the 2 columns of interest from training set.\n",
    "train_features = train_df[['accommodates', 'bathrooms']]\n",
    "# List-like object, containing just the target column, `price`.\n",
    "train_target = train_df['price']\n",
    "# Pass everything into the fit method.\n",
    "knn.fit(train_features, train_target)\n",
    "\n",
    "predictions = knn.predict(test_df[['accommodates', 'bathrooms']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Calculating MSE using Scikit-Learn\n",
    "==\n",
    "\n",
    "Earlier in this mission, we calculated the MSE and RMSE values using the pandas arithmetic operators to compare each predicted value with the actual value from the <span style=\"background-color: #F9EBEA; color:##C0392B\">price</span> column of our test set. Alternatively, we can instead use the [sklearn.metrics.mean_squared_error function()](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error). Once you become familiar with the different machine learning concepts, unifying your workflow using scikit-learn helps save you a lot of time and avoid mistakes.\n",
    "\n",
    "The <span style=\"background-color: #F9EBEA; color:##C0392B\">mean_squared_error()</span> function takes in 2 inputs:\n",
    "\n",
    "- list-like object, representing the true values\n",
    "- list-like object, representing the predicted values using the model\n",
    "\n",
    "For this function, we won't show any sample code and will leave it to you to understand the function [from the documentation](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) itself to calculate the MSE and RMSE values for the predictions we just made.\n",
    "\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise Start.</b>\n",
    "</div>\n",
    "\n",
    "**Description**: \n",
    "\n",
    "1. Use the <span style=\"background-color: #F9EBEA; color:##C0392B\">mean_squared_error</span> function to calculate the MSE value for the predictions we made in the previous screen.\n",
    "2. Assign the MSE value to <span style=\"background-color: #F9EBEA; color:##C0392B\">two_features_mse</span>.\n",
    "3. Calculate the RMSE value by taking the square root of the MSE value and assign to <span style=\"background-color: #F9EBEA; color:##C0392B\">two_features_rmse</span>.\n",
    "4. Display both of these error scores using the <span style=\"background-color: #F9EBEA; color:##C0392B\">print</span> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15184.425165\n",
      "123.225099574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_columns = ['accommodates', 'bathrooms']\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute', metric='euclidean')\n",
    "knn.fit(train_df[train_columns], train_df['price'])\n",
    "predictions = knn.predict(test_df[train_columns])\n",
    "\n",
    "two_features_mse = mean_squared_error(predictions, test_df['price'])\n",
    "two_features_rmse = np.sqrt(two_features_mse)\n",
    "print(two_features_mse)\n",
    "print(two_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Using more features\n",
    "==\n",
    "\n",
    "Here's a table comparing the MSE and RMSE values for the 2 univariate models from the last mission and the multivariate model we just trained:\n",
    "\n",
    "| feature(s)              | MSE     | RMSE  |\n",
    "|-------------------------|---------|-------|\n",
    "| accommodates            | 18646.5 | 136.6 |\n",
    "| bathrooms               | 17333.4 | 131.7 |\n",
    "| accommodates, bathrooms | 15660.4 | 125.1 |\n",
    "\n",
    "As you can tell, the model we trained using both features ended up performing better (lower error score) than either of the univariate models from the last mission. Let's now train a model using the following 4 features:\n",
    "\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">accommodates</span>\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">bedrooms</span>\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">bathrooms</span>\n",
    "- <span style=\"background-color: #F9EBEA; color:##C0392B\">number_of_reviews</span>\n",
    "\n",
    "Scikit-learn makes it incredibly easy to swap the columns used during training and testing. We're going to leave this for you as a challenge to train and test a k-nearest neighbors model using these columns instead. Use the code you wrote in the last screen as a guide.\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise Start.</b>\n",
    "</div>\n",
    "\n",
    "**Description**: \n",
    "\n",
    "\n",
    "1. Create a new instance of the [KNeighborsRegressor class](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor) with the following parameters:\n",
    "    - <span style=\"background-color: #F9EBEA; color:##C0392B\">n_neighbors</span>: 5\n",
    "    - <span style=\"background-color: #F9EBEA; color:##C0392B\">algorithm</span>: brute\n",
    "2. Fit a model that uses the following columns from our training set (**train_df**):\n",
    "    - <span style=\"background-color: #F9EBEA; color:##C0392B\">accommodates</span>\n",
    "    - <span style=\"background-color: #F9EBEA; color:##C0392B\">bedrooms</span>\n",
    "    - <span style=\"background-color: #F9EBEA; color:##C0392B\">bathrooms</span>\n",
    "    - <span style=\"background-color: #F9EBEA; color:##C0392B\">number_of_reviews</span>\n",
    "3. Use the model to make predictions on the test set (**test_df**) using the same columns. Assign the NumPy array of predictions to <span style=\"background-color: #F9EBEA; color:##C0392B\">four_predictions</span>.\n",
    "4. Use the <span style=\"background-color: #F9EBEA; color:##C0392B\">mean_squared_error()</span> function to calculate the MSE value for these predictions by comparing <span style=\"background-color: #F9EBEA; color:##C0392B\">four_predictions</span> with the price column from **test_df**. Assign the computed MSE value to <span style=\"background-color: #F9EBEA; color:##C0392B\">four_mse</span>.\n",
    "5. Calculate the RMSE value and assign to <span style=\"background-color: #F9EBEA; color:##C0392B\">four_rmse</span>.\n",
    "6. Display <span style=\"background-color: #F9EBEA; color:##C0392B\">four_mse</span> and <span style=\"background-color: #F9EBEA; color:##C0392B\">four_rmse</span> using the print function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13474.4033675\n",
      "116.079297756\n"
     ]
    }
   ],
   "source": [
    "train_columns = ['accommodates', 'bathrooms', 'bedrooms', 'number_of_reviews']\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute', metric='euclidean')\n",
    "knn.fit(train_df[train_columns], train_df['price'])\n",
    "four_predictions = knn.predict(test_df[train_columns])\n",
    "\n",
    "four_features_mse = mean_squared_error(four_predictions, test_df['price'])\n",
    "four_features_rmse = np.sqrt(four_features_mse)\n",
    "print(four_features_mse)\n",
    "print(four_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Using all features\n",
    "==\n",
    "\n",
    "So far so good! As we increased the features the model used, we observed lower MSE and RMSE values:\n",
    "\n",
    "| feature(s)                                           | MSE     | RMSE  |\n",
    "|------------------------------------------------------|---------|-------|\n",
    "| accommodates                                         | 18646.5 | 136.6 |\n",
    "| bathrooms                                            | 17333.4 | 131.7 |\n",
    "| accommodates, bathrooms                              | 15660.4 | 125.1 |\n",
    "| accommodates, bathrooms, bedrooms, number_of_reviews | 13320.2 | 115.4 |\n",
    "\n",
    "Let's take this to the extreme and use all of the potential features. We should expect the error scores to decrease since so far adding more features has helped do so.\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise Start.</b>\n",
    "</div>\n",
    "\n",
    "**Description**: \n",
    "\n",
    "1. Use all of the columns, except for the <span style=\"background-color: #F9EBEA; color:##C0392B\">price</span> column, to train a k-nearest neighbors model using the same parameters for the <span style=\"background-color: #F9EBEA; color:##C0392B\">KNeighborsRegressor</span> class as the ones from the last few screens.\n",
    "2. Use the model to make predictions on the test set and assign the resulting NumPy array of predictions to <span style=\"background-color: #F9EBEA; color:##C0392B\">all_features_predictions</span>.\n",
    "3. Calculate the MSE and RMSE values and assign to <span style=\"background-color: #F9EBEA; color:##C0392B\">all_features_mse</span> and <span style=\"background-color: #F9EBEA; color:##C0392B\">all_features_rmse</span> accordingly.\n",
    "4. Use the **print** function to display both error scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accommodates', 'bedrooms', 'bathrooms', 'beds', 'price',\n",
       "       'minimum_nights', 'maximum_nights', 'number_of_reviews'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15392.6253925\n",
      "124.067019761\n"
     ]
    }
   ],
   "source": [
    "train_columns = ['accommodates', 'bedrooms', 'bathrooms', 'beds', 'minimum_nights', 'maximum_nights', 'number_of_reviews']\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute', metric='euclidean')\n",
    "knn.fit(train_df[train_columns], train_df['price'])\n",
    "all_features_predictions = knn.predict(test_df[train_columns])\n",
    "\n",
    "all_features_mse = mean_squared_error(all_features_predictions, test_df['price'])\n",
    "all_features_rmse = np.sqrt(all_features_mse)\n",
    "print(all_features_mse)\n",
    "print(all_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Next steps\n",
    "==\n",
    "\n",
    "Interestingly enough, the RMSE value actually increased to **125.1** when we used all of the features available to us. This means that selecting the right features is important and that using more features doesn't automatically improve prediction accuracy. We should re-phrase the lever we mentioned earlier from:\n",
    "\n",
    "- increase the number of attributes the model uses to calculate similarity when ranking the closest neighbors\n",
    "\n",
    "to:\n",
    "\n",
    "- select the relevant attributes the model uses to calculate similarity when ranking the closest neighbors\n",
    "\n",
    "The process of selecting features to use in a model is known as **feature selection**.\n",
    "\n",
    "In this mission, we prepared the data to be able to use more features, trained a few models using multiple features, and evaluated the different performance tradeoffs. We explored how using more features doesn't always improve the accuracy of a k-nearest neighbors model. In the next mission, we'll explore another knob for tuning k-nearest neighbor models - the k value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f22e88e9e10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa4AAAFGCAYAAAAy4nt1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22e88f49b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.heatmap(dc_listings.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False False False False]\n",
      "[1 1 1 2 4 5 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3)\n",
    "train_columns = ['accommodates', 'bedrooms', 'bathrooms', 'beds', 'minimum_nights', 'maximum_nights', 'number_of_reviews']\n",
    "rfe = rfe.fit(train_df[train_columns], train_df['price'])\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13407.8356769\n",
      "115.792209051\n"
     ]
    }
   ],
   "source": [
    "train_columns = ['accommodates', 'bedrooms', 'bathrooms']\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute', metric='euclidean')\n",
    "knn.fit(train_df[train_columns], train_df['price'])\n",
    "all_features_predictions = knn.predict(test_df[train_columns])\n",
    "\n",
    "all_features_mse = mean_squared_error(all_features_predictions, test_df['price'])\n",
    "all_features_rmse = np.sqrt(all_features_mse)\n",
    "print(all_features_mse)\n",
    "print(all_features_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
